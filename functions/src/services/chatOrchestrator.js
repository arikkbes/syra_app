/**
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * CHAT ORCHESTRATOR - FIXED + STABLE VERSION (FINAL)
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * Handles all chat logic, trait extraction, persona building,
 * OpenAI calls and Firestore-safe conversation history saving.
 */

import { openai } from "../config/openaiClient.js";
import { detectIntentType, getChatConfig } from "../domain/intentEngine.js";
import { buildUltimatePersona, normalizeTone, isRelationshipQuery } from "../domain/personaEngine.js";
import { extractDeepTraits } from "../domain/traitEngine.js";
import { predictOutcome } from "../domain/outcomePredictionEngine.js";
import { detectUserPatterns } from "../domain/patternEngine.js";
import { detectGenderSmart } from "../domain/genderEngine.js";
import { 
  analyzeTurkishCulturalContext,
  extractContextFromMessage,
  generateRedFlagSummary
} from "../domain/turkishCultureEngine.js"; // MODULE 3
import { 
  MODEL_FALLBACK,
  MAX_RETRY_ATTEMPTS,
  RETRY_BASE_DELAY_MS,
  RETRY_MAX_JITTER_MS
} from "../utils/constants.js";

import {
  getUserProfile,
  updateUserProfile,
  incrementGenderAttempts,
  updateUserGender,
} from "../firestore/userProfileRepository.js";

import {
  getConversationHistory,
  saveConversationHistory,
} from "../firestore/conversationRepository.js";

import { db as firestore } from "../config/firebaseAdmin.js";
import { getRelationshipContext } from "./relationshipRetrieval.js";

/**
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * MODULE 2.5: RETRY HELPER WITH EXPONENTIAL BACKOFF + JITTER
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 */
async function sleep(ms) {
  return new Promise(resolve => setTimeout(resolve, ms));
}

function getRetryDelay(attemptNumber) {
  // Exponential backoff: 2^attempt * base delay
  const exponentialDelay = Math.pow(2, attemptNumber) * RETRY_BASE_DELAY_MS;
  // Add random jitter to prevent thundering herd
  const jitter = Math.random() * RETRY_MAX_JITTER_MS;
  return exponentialDelay + jitter;
}

function isRetryableError(error) {
  if (!error) return false;
  
  const errorMessage = error?.message?.toLowerCase() || '';
  const errorCode = error?.status || error?.code;
  
  // Retry on rate limits
  if (errorCode === 429 || errorMessage.includes('rate limit')) {
    return true;
  }
  
  // Retry on 5xx server errors
  if (errorCode >= 500 && errorCode < 600) {
    return true;
  }
  
  // Retry on network timeouts
  if (errorMessage.includes('timeout') || 
      errorMessage.includes('econnreset') ||
      errorMessage.includes('network')) {
    return true;
  }
  
  return false;
}

/**
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * MODULE 2.5: ROBUST OPENAI CALL WITH RETRY + FALLBACK
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 */
async function callOpenAIWithRetry(uid, model, messages, maxTokens) {
  let lastError = null;
  let currentModel = model;
  let usedFallback = false;
  
  // Try primary model with retries
  for (let attempt = 0; attempt < MAX_RETRY_ATTEMPTS; attempt++) {
    try {
      console.log(`[${uid}] [OPENAI_ATTEMPT] Attempt ${attempt + 1}/${MAX_RETRY_ATTEMPTS} with model ${currentModel}`);
      
      const completion = await openai.chat.completions.create({
        model: currentModel,
        messages: messages,
        max_completion_tokens: maxTokens,
        temperature: 0.4,
      });
      
      // Check for empty completion
      if (!completion?.choices?.[0]?.message?.content) {
        throw new Error('EMPTY_COMPLETION');
      }
      
      const replyText = completion.choices[0].message.content.trim();
      
      if (!replyText || replyText.length < 5) {
        throw new Error('EMPTY_COMPLETION');
      }
      
      console.log(`[${uid}] âœ… OpenAI success â†’ Model: ${currentModel}, Reply length: ${replyText.length}`);
      
      return {
        replyText,
        model: currentModel,
        originalModel: model,
        usedFallback,
        hadError: false,
      };
      
    } catch (error) {
      lastError = error;
      const errorMessage = error?.message || 'Unknown error';
      const errorStatus = error?.status || error?.code || 'N/A';
      
      console.error(`[${uid}] [OPENAI_RETRY] Attempt ${attempt + 1} failed â†’ Status: ${errorStatus}, Error: ${errorMessage}`);
      
      // Check if this is retryable
      const shouldRetry = isRetryableError(error) || errorMessage.includes('EMPTY_COMPLETION');
      
      if (shouldRetry && attempt < MAX_RETRY_ATTEMPTS - 1) {
        const delay = getRetryDelay(attempt);
        console.log(`[${uid}] [OPENAI_RETRY] Waiting ${Math.round(delay)}ms before retry ${attempt + 2}`);
        await sleep(delay);
        continue; // Try again with same model
      }
      
      // If we've exhausted retries, break and try fallback
      break;
    }
  }
  
  // If primary model failed after all retries, try fallback model
  if (currentModel !== MODEL_FALLBACK) {
    console.log(`[${uid}] [OPENAI_FALLBACK_MODEL] Primary model ${currentModel} failed after ${MAX_RETRY_ATTEMPTS} attempts. Trying fallback: ${MODEL_FALLBACK}`);
    
    try {
      // Trim messages to reduce payload size for fallback
      const trimmedMessages = messages.length > 10 
        ? [...messages.slice(0, 5), ...messages.slice(-5)] // Keep first 5 and last 5
        : messages;
      
      const completion = await openai.chat.completions.create({
        model: MODEL_FALLBACK,
        messages: trimmedMessages,
        max_completion_tokens: Math.min(maxTokens, 800), // Reduce token limit for fallback
        temperature: 0.4,
      });
      
      if (!completion?.choices?.[0]?.message?.content) {
        throw new Error('EMPTY_COMPLETION');
      }
      
      const replyText = completion.choices[0].message.content.trim();
      
      if (!replyText || replyText.length < 5) {
        throw new Error('EMPTY_COMPLETION');
      }
      
      console.log(`[${uid}] âœ… [OPENAI_FALLBACK_MODEL] Fallback successful â†’ Model: ${MODEL_FALLBACK}, Reply length: ${replyText.length}`);
      
      return {
        replyText,
        model: MODEL_FALLBACK,
        originalModel: model,
        usedFallback: true,
        hadError: false,
      };
      
    } catch (fallbackError) {
      console.error(`[${uid}] [OPENAI_FINAL_FAIL] Fallback model also failed â†’ ${fallbackError?.message}`);
      lastError = fallbackError;
    }
  }
  
  // All attempts failed
  console.error(`[${uid}] [OPENAI_FINAL_FAIL] All retry attempts exhausted. Last error: ${lastError?.message}`);
  
  return {
    replyText: null,
    model: currentModel,
    originalModel: model,
    usedFallback,
    hadError: true,
    errorType: lastError?.message || 'UNKNOWN_OPENAI_ERROR',
  };
}

/**
 * MAIN CHAT PROCESSOR
 * @param {string} uid
 * @param {string} sessionId - Session ID for scoped history (MODULE 1)
 * @param {string} message
 * @param {string} replyTo
 * @param {boolean} isPremium
 * @param {string} imageUrl - Optional image URL for vision analysis
 * @param {string} mode - Conversation mode: 'standard', 'deep', 'mentor'
 * @param {string} tarotContext - Optional tarot reading context for follow-up questions
 */
export async function processChat(uid, sessionId, message, replyTo, isPremium, imageUrl = null, mode = 'standard', tarotContext = null) {
  const startTime = Date.now();

  // SAFETY: Make sure OpenAI client exists
  if (!openai) {
    console.error(`[${uid}] ğŸ”¥ CRITICAL: OpenAI client missing (API key invalid).`);
    throw new Error("OpenAI not configured - missing API key");
  }

  // Safe message
  const safeMessage = String(message).slice(0, 5000);
  
  // Log tarot context if present
  if (tarotContext) {
    console.log(`[${uid}] Processing tarot follow-up question`);
  }

  // Load user + history
  const [userProfile, rawHistory] = await Promise.all([
    getUserProfile(uid),
    getConversationHistory(uid, sessionId), // MODULE 1: Pass sessionId
  ]);

  const history = rawHistory?.messages || [];
  const conversationSummary = rawHistory?.summary || null;
  
  // TASK B: Gender pronoun for guidance messages
  const gender = userProfile.gender || "belirsiz";
  const genderPronoun = gender === "erkek" ? "kardeÅŸim" : gender === "kadÄ±n" ? "kanka" : "kanka";

  console.log(
    `[${uid}] Processing - Session: ${sessionId}, Premium: ${isPremium}, Mode: ${mode}, History: ${history.length}, Summary: ${!!conversationSummary}`
  );

  // Intent detection
  const intent = detectIntentType(safeMessage, history);
  let { model, temperature, maxTokens } = getChatConfig(
    intent,
    isPremium,
    userProfile
  );

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // VISION MODEL OVERRIDE: EÄŸer resim varsa, vision destekli model kullan
  // gpt-4o models support vision
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  if (imageUrl) {
    // gpt-4o models support vision
    if (model === "gpt-4o-mini") {
      model = isPremium ? "gpt-4o" : "gpt-4o-mini";
      console.log(`[${uid}] Model kept for vision â†’ ${model}`);
    }
  }

  console.log(
    `[${uid}] Intent: ${intent}, Model: ${model}, Temp: ${temperature}, MaxTokens: ${maxTokens}, Image: ${!!imageUrl}`
  );

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // MODULE 3: Deep Analysis Trigger Detection
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  let turkishCultureAnalysis = null;
  let shouldDeepAnalyze = false;
  
  if (intent === "deep_relationship_issue" || intent === "pattern_analysis") {
    console.log(`[${uid}] ğŸ”¬ MODULE 3: Deep analysis triggered - Intent: ${intent}`);
    shouldDeepAnalyze = true;
    
    // Extract context from message
    const extractedContext = extractContextFromMessage(safeMessage);
    
    // Analyze with Turkish culture engine
    turkishCultureAnalysis = analyzeTurkishCulturalContext(extractedContext);
    
    console.log(`[${uid}] ğŸš© MODULE 3: Detected ${turkishCultureAnalysis.length} red flag pattern(s)`);
    
    if (turkishCultureAnalysis.length > 0) {
      turkishCultureAnalysis.forEach(flag => {
        console.log(`[${uid}]    - ${flag.type} (${flag.severity})`);
      });
    }
  }

  // Gender detection
  let detectedGender = await detectGenderSmart(safeMessage, userProfile);

  if (detectedGender !== userProfile.gender && detectedGender !== "belirsiz") {
    await updateUserGender(uid, detectedGender);
    userProfile.gender = detectedGender;
    console.log(`[${uid}] Gender updated â†’ ${detectedGender}`);
  } else if (detectedGender === "belirsiz" && userProfile.genderAttempts < 3) {
    await incrementGenderAttempts(uid);
  }

  // Trait extraction
  const extractedTraits = await extractDeepTraits(
    safeMessage,
    replyTo,
    history
  );

  console.log(
    `[${uid}] Traits â†’ Tone: ${extractedTraits.tone}, Urgency: ${extractedTraits.urgency}, Flags: R${extractedTraits.flags.red.length}/G${extractedTraits.flags.green.length}`
  );

  // Pattern detection
  const patterns = await detectUserPatterns(history, userProfile, isPremium);

  if (patterns) {
    console.log(
      `[${uid}] Patterns â†’ Mistakes: ${patterns.repeatingMistakes?.length || 0}, Type: ${patterns.relationshipType}`
    );
  }

  // Outcome prediction
  const outcomePrediction = await predictOutcome(
    safeMessage,
    history,
    isPremium
  );

  if (outcomePrediction) {
    console.log(
      `[${uid}] Outcome â†’ Interest: ${outcomePrediction.interestLevel}% / Date: ${outcomePrediction.dateProbability}%`
    );
  }

  // Update user profile
  userProfile.lastTone = normalizeTone(extractedTraits.tone);

  if (
    extractedTraits.relationshipStage &&
    extractedTraits.relationshipStage !== "none"
  ) {
    userProfile.relationshipStage = extractedTraits.relationshipStage;
  }

  if (
    extractedTraits.attachmentStyle &&
    extractedTraits.attachmentStyle !== "unknown"
  ) {
    userProfile.attachmentStyle = extractedTraits.attachmentStyle;
  }

  userProfile.totalAdviceGiven = (userProfile.totalAdviceGiven || 0) + 1;

  updateUserProfile(uid, userProfile).catch((e) =>
    console.error(`[${uid}] UserProfile update error â†’`, e)
  );

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // STEP 1 & 2: Detect if query is relationship-related
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  const isRelQuery = isRelationshipQuery(safeMessage);
  let hasActiveRelationship = false;

  // Reply context
  const replyContext = replyTo
    ? `
ğŸ¯ Ã–ZEL YANIT MODU:
KullanÄ±cÄ± ÅŸu mesaja yanÄ±t veriyor: "${String(replyTo).slice(0, 400)}"
CevabÄ±nÄ± buna gÃ¶re kurgula.
`
    : "Normal sohbet modu.";

  // Enriched long context (Premium only)
  const enrichedContext =
    isPremium && (history.length > 5 || conversationSummary)
      ? `
ğŸ“Š CONTEXT:
â€¢ Summary: ${conversationSummary || "yok"}
â€¢ Mesaj sayÄ±sÄ±: ${userProfile.messageCount}
â€¢ Stage: ${userProfile.relationshipStage}
â€¢ Attachment: ${userProfile.attachmentStyle}
`
      : "";

  // System messages - persona will be added after relationship context check
  const systemMessages = [
    { role: "system", content: replyContext },
  ];

  if (enrichedContext) {
    systemMessages.push({ role: "system", content: enrichedContext });
  }

  // Tone and emotional adjustments
  if (
    extractedTraits.urgency === "high" ||
    extractedTraits.urgency === "critical"
  ) {
    systemMessages.push({
      role: "system",
      content: "âš ï¸ ACÄ°L: Daha net ve hÄ±zlÄ± Ã§Ã¶zÃ¼m odaklÄ± cevap ver.",
    });
  }

  if (extractedTraits.needsSupport) {
    systemMessages.push({
      role: "system",
      content:
        "ğŸ’™ KullanÄ±cÄ± duygusal destek istiyor. YumuÅŸak ve empatik ol.",
    });
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // MODULE 3: Deep Analysis Context Injection
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  if (shouldDeepAnalyze && turkishCultureAnalysis && turkishCultureAnalysis.length > 0) {
    const redFlagSummary = generateRedFlagSummary(turkishCultureAnalysis);
    
    systemMessages.push({
      role: "system",
      content: `
ğŸ”¬ DERIN ANALÄ°Z MODU AKTÄ°F (MODULE 3)

KullanÄ±cÄ± iliÅŸkisinde ciddi pattern'ler tespit edildi.
TÃ¼rk kÃ¼ltÃ¼rÃ¼ baÄŸlamÄ±nda ÅŸu red flag'ler var:

${redFlagSummary}

Ã–NEMLÄ° TALIMATLAR:
1. Bu pattern'leri kullanÄ±cÄ±ya aÃ§Ä±kla (yargÄ±lamadan)
2. TÃ¼rk kÃ¼ltÃ¼rÃ¼ baÄŸlamÄ±nÄ± ver (neden bu Ã¶nemli?)
3. Somut aksiyon adÄ±mlarÄ± Ã¶ner
4. Empati gÃ¶ster ama gerÃ§ekÃ§i ol
5. Red flag ciddiyse, net sÃ¶yle

EÄŸer relationship context aktifse, ZIP'ten mesaj Ã¶rnekleri de gÃ¶ster.
      `.trim()
    });
    
    console.log(`[${uid}] ğŸ”¬ MODULE 3: Deep analysis context injected into system prompt`);
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // MODULE 3.1: Intent-Based Question Policy
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  if (intent === "greeting") {
    // MODULE 3.1.1 HOTFIX 1: Natural greeting with ONE greeting question
    systemMessages.push({
      role: "system",
      content: `
ğŸ’¬ GREETING MODE (MODULE 3.1.1 HOTFIX)

User sent a simple greeting (selam, naber, etc.).
Your response:
"Ä°yiyim kanka. Sende naber?"

RULES:
âœ… ONE natural greeting question: "Sende naber?" or "Sen nasÄ±lsÄ±n?"
âŒ NO generic topic questions: "Ne hakkÄ±nda konuÅŸalÄ±m?"
âŒ NO extended conversation prompts

Keep it SHORT and NATURAL.
      `.trim()
    });
  } else if (intent === "message_drafting") {
    // MODULE 3.1.1 HOTFIX 3: Multi-choice question for message drafting
    systemMessages.push({
      role: "system",
      content: `
ğŸ¯ MESSAGE DRAFTING MODE (MODULE 3.1.1 HOTFIX)

User wants help writing a message.

STEP 1: Ask ONE multi-choice question (if context missing):
"Kanka 1) yeni tanÄ±ÅŸtÄ±nÄ±z 2) flÃ¶rt 3) sevgili 4) ex â€” hangisi?
 Hedef: A) ilgiyi artÄ±r B) randevu C) sÄ±nÄ±r koy D) barÄ±ÅŸ"

STEP 2: Immediately provide 2-3 draft options anyway (don't wait):
- Soft: [yumuÅŸak versiyon]
- Cool: [rahat versiyon]
- Spicy: [flÃ¶rt/cesur versiyon]

Max 1 question. Always provide drafts even before user answers.

FORBIDDEN:
âŒ "Ne hakkÄ±nda konuÅŸmak istersin?"
âŒ "BaÅŸka bir ÅŸey var mÄ±?"
      `.trim()
    });
  } else if (intent === "context_missing") {
    systemMessages.push({
      role: "system",
      content: `
ğŸ” CONTEXT MISSING MODE (MODULE 3.1)

User wants help but request is vague. Your response:
1. Make reasonable assumption
2. Provide solution based on assumption
3. If truly critical info missing, ask 1 specific question

ALLOWED QUESTION (max 1):
âœ… "Hangi iliÅŸkiden bahsediyorsun?"
âœ… "Kime/neyle ilgili bu?"

THEN provide direct advice. Don't wait for answer.
      `.trim()
    });
  } else if (intent === "deep_relationship_issue" || intent === "pattern_analysis") {
    // MODULE 3.1.1 HOTFIX 2: Evidence-gated question policy
    const hasEvidence = relationshipData && relationshipData.hasRetrieval && 
                       relationshipData.context && relationshipData.context.includes("ğŸ“ ALAKALI SOHBET");
    
    if (hasEvidence) {
      // Evidence exists - NO questions allowed
      systemMessages.push({
        role: "system",
        content: `
ğŸ”¬ DEEP ANALYSIS MODE - EVIDENCE AVAILABLE (MODULE 3.1.1)

You have concrete evidence from relationship messages.
Provide grounded analysis WITHOUT asking questions.

Use probabilistic language:
âœ… "Mesajlara bakÄ±nca [pattern] gÃ¶rÃ¼yorum"
âœ… "X kez bu davranÄ±ÅŸ var"
âœ… "Bu [pattern]'e benziyor"
âŒ "Kesinlikle manipÃ¼lasyon" (unless evidence is very strong)

Provide analysis + action steps directly.
NO QUESTIONS.
        `.trim()
      });
    } else {
      // No evidence - Allow 1 targeted question
      systemMessages.push({
        role: "system",
        content: `
ğŸ”¬ DEEP ANALYSIS MODE - NO EVIDENCE (MODULE 3.1.1)

No ZIP messages available for this relationship.
You can ask ONE targeted clarification question to reduce hallucination.

ALLOWED (max 1 targeted question):
âœ… "Bu istek haftada kaÃ§ kez oluyor?"
âœ… "Sen 'hayÄ±r' deyince trip/guilt yapÄ±yor mu?"
âœ… "KarÅŸÄ±lÄ±klÄ± mÄ± yoksa tek taraflÄ± mÄ±?"

FORBIDDEN:
âŒ "Ne hakkÄ±nda konuÅŸmak istersin?"
âŒ "Daha fazla bilgi verir misin?"

CRITICAL: After question, immediately provide boundary-setting suggestion.
Do NOT wait for answer. Give both question AND advice in same message.

Use probabilistic language:
âœ… "Bu [pattern]'e benziyor"
âœ… "Olabilir"
âŒ "Kesinlikle manipÃ¼lasyon"
        `.trim()
      });
    }
  } else if (intent === "normal") {
    // Small talk / normal conversation
    systemMessages.push({
      role: "system",
      content: `
ğŸ’¬ NORMAL CONVERSATION MODE - NO QUESTIONS (MODULE 3.1)

This is small talk or casual conversation.
Keep response SHORT (1-2 sentences).
NO follow-up questions.

Examples:
User: "Naber"
âœ… "Ä°yi kanka."
âŒ "Ä°yiyim! Sen nasÄ±lsÄ±n? Ne yapÄ±yorsun?"

User: "Ä°yiyim"
âœ… "GÃ¼zel. Bir sorun olursa sÃ¶yle."
âŒ "Ä°yi! Neyle ilgileniyorsun?"
      `.trim()
    });
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // UPLOAD GUIDANCE GUARD: Detect upload questions and give UI instructions only
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  const uploadKeywords = [
    "nereden yÃ¼kle", "nasÄ±l yÃ¼kle", "iliÅŸki yÃ¼kleme", "iliÅŸkiyi yÃ¼kle",
    "upload", "zip", "whatsapp sohbet", "sohbeti yÃ¼kle", "dosya yÃ¼kle",
    "nereye yÃ¼kle", "nasÄ±l ekle"
  ];
  
  const abKeywords = [
    "a ve b ne", "a b ne demek", "a veya b", "a/b ne", "kim a kim b",
    "a kimdir", "b kimdir", "a ile b"
  ];
  
  const messageLower = message.toLowerCase();
  const isUploadQuestion = uploadKeywords.some(keyword => messageLower.includes(keyword));
  const isAbQuestion = abKeywords.some(keyword => messageLower.includes(keyword));
  
  if (isUploadQuestion) {
    systemMessages.push({
      role: "system",
      content: `
ğŸ”’ UPLOAD GUIDANCE OVERRIDE:
User is asking how to upload relationship. Give ONLY these UI instructions (short, confident, 1-3 sentences):

1) "Ä°liÅŸkiyi yÃ¼klemek iÃ§in chat bar'daki SYRA logosuna dokun."
2) "WhatsApp sohbet ZIP veya .txt dosyanÄ± seÃ§ ve yÃ¼kle."
3) "YÃ¼kledikten sonra panelden 'Chat'te kullan'Ä± aÃ§."

Do NOT ask for names, details, or relationship info. Just give UI steps.
      `.trim(),
    });
  }
  
  if (isAbQuestion) {
    systemMessages.push({
      role: "system",
      content: `
ğŸ”’ A/B EXPLANATION OVERRIDE:
User is asking what A/B means. Give a brief, friendly explanation (1-2 sentences):

"A ve B, WhatsApp sohbetinde ilk yazan ve ikinci yazan kiÅŸiyi temsil eder. 'Ben A'yÄ±m' veya 'Ben B'yim' diyerek seÃ§im yapabilirsin, ya da panelden kendin belirleyebilirsin."

Keep it simple and actionable.
      `.trim(),
    });
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // RESPONSE STYLE ENFORCEMENT: ChatGPT-quality concise responses
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  systemMessages.push({
    role: "system",
    content: `
âš¡ STYLE REMINDER (CRITICAL):
â€¢ Keep responses SHORT: 1-2 sentences default
â€¢ NO filler phrases: "BuradayÄ±m", "Seni dinliyorum", "YardÄ±mcÄ± olabilirim", etc.
â€¢ MAX 1 question per response
â€¢ NO repeated greetings (only greet once per new chat)
â€¢ Direct action framing: "Tamam. Åunu yap: â€¦"
â€¢ Only expand if user asks or situation requires detail
    `.trim(),
  });

  const recentHistory = history.slice(-10);

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // TAROT CONTEXT: If this is a follow-up about a tarot reading
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  if (tarotContext) {
    systemMessages.push({
      role: "system",
      content: `ğŸ”® TAROT CONTEXT:\n${tarotContext}\n\nÅimdi kullanÄ±cÄ± bu tarot aÃ§Ä±lÄ±mÄ± hakkÄ±nda soru soruyor. AÃ§Ä±lÄ±mdaki kartlarÄ± ve yorumu referans alarak cevap ver. Tarot yorumcusu gibi konuÅŸ - spesifik, pattern-based, dÃ¼rÃ¼st.`,
    });
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // RELATIONSHIP MEMORY V2: Smart retrieval with chunked storage
  // STEP 2 FIX: Proper gating - only use if isActive=true
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  let relationshipData = null;
  try {
    relationshipData = await getRelationshipContext(uid, safeMessage, history);
    
    // STEP 2: Relationship MUST be active to use context
    if (relationshipData && relationshipData.context) {
      hasActiveRelationship = true;
      
      // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      // AUTO-PERSIST SELFPARTICIPANT
      // If selfParticipant is missing, detect if user is answering the clarification question
      // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      if (!relationshipData.selfParticipant && relationshipData.speakers && relationshipData.speakers.length >= 2) {
        const { detectSelfParticipantFromMessage, persistSelfParticipant, getActiveRelationshipContext, buildParticipantContextPrompt } = await import("./relationshipContext.js");
        
        const detectedSpeaker = detectSelfParticipantFromMessage(safeMessage, relationshipData.speakers);
        
        if (detectedSpeaker) {
          console.log(`[${uid}] ğŸ¯ Detected self-participant from message: ${detectedSpeaker}`);
          
          // Persist to Firestore
          const persistSuccess = await persistSelfParticipant(
            uid,
            relationshipData.relationshipId,
            detectedSpeaker,
            relationshipData.speakers
          );
          
          if (persistSuccess) {
            console.log(`[${uid}] âœ… Auto-set selfParticipant to: ${detectedSpeaker}`);
            
            // Rebuild relationship context with updated participant mapping
            const updatedContext = await getActiveRelationshipContext(uid);
            if (updatedContext) {
              relationshipData.selfParticipant = updatedContext.selfParticipant;
              relationshipData.partnerParticipant = updatedContext.partnerParticipant;
              
              // Rebuild participant context prompt
              relationshipData.participantContext = buildParticipantContextPrompt(updatedContext);
              
              console.log(`[${uid}] ğŸ”„ Rebuilt participant context with USER=${updatedContext.selfParticipant}, PARTNER=${updatedContext.partnerParticipant}`);
            }
          }
        }
      }
      
      // Inject relationship context
      systemMessages.push({
        role: "system",
        content: relationshipData.context,
      });
      
      // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      // PATCH C: Detect relationship context change and inject override
      // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      const shouldInjectOverride = await checkRelationshipContextChange(
        uid,
        relationshipData.relationshipId,
        relationshipData.updatedAt
      );
      
      if (shouldInjectOverride) {
        systemMessages.push({
          role: "system",
          content: `
ğŸ”„ RELATIONSHIP CONTEXT UPDATED (CRITICAL):
The active relationship has just been changed or toggled ON.
IGNORE any previous assumptions about who is who from earlier in this chat.
Use ONLY the current relationship participants provided above:
- USER = ${relationshipData.selfParticipant || 'to be determined'}
- PARTNER = ${relationshipData.partnerParticipant || 'to be determined'}

Previous partner names or relationship details from earlier turns are now INVALID.
Base all responses on the CURRENT active relationship context only.
          `.trim(),
        });
        console.log(`[${uid}] ğŸ”„ Relationship context change detected - override injected`);
      }
      
      // CRITICAL: Inject participant mapping context
      if (relationshipData.participantContext) {
        systemMessages.push({
          role: "system",
          content: relationshipData.participantContext,
        });
      }
      
      console.log(`[${uid}] ğŸ“± Relationship context loaded (retrieval: ${relationshipData.hasRetrieval}, participant mapping: ${!!relationshipData.participantContext})`);
    } else {
      // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      // STEP 2: No active relationship - check if user is asking about messages
      // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      const readMessagesKeywords = [
        "son mesaj", "last message", "mesajlarÄ± oku", "read messages",
        "mesajlarÄ± gÃ¶r", "mesajlarÄ± incele", "mesajlara bak", "konuÅŸmalarÄ± oku",
        "yazÄ±ÅŸmalarÄ± oku", "sohbetleri oku"
      ];
      const messageLower = safeMessage.toLowerCase();
      const isAskingForMessages = readMessagesKeywords.some(k => messageLower.includes(k));
      
      // TASK B: Don't inject system prompt, handle in response below
      if (isAskingForMessages && isRelQuery) {
        console.log(`[${uid}] âš ï¸ User asking for messages but no active relationship`);
      } else if (history.length > 0 && isRelQuery) {
        console.log(`[${uid}] ğŸš« No active relationship but relationship query detected`);
      }
    }
  } catch (memErr) {
    console.error(`[${uid}] Failed to load relationship context (non-critical):`, memErr);
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // STEP 1 & 2: Build persona AFTER relationship context check
  // Persona needs to know hasActiveRelationship status
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  const persona = buildUltimatePersona(
    isPremium,
    userProfile,
    extractedTraits,
    patterns,
    conversationSummary,
    mode,
    hasActiveRelationship,
    isRelQuery
  );
  
  // Inject persona at the beginning of system messages
  systemMessages.unshift({ role: "system", content: persona });
  
  console.log(`[${uid}] Persona built: hasActiveRelationship=${hasActiveRelationship}, isRelQuery=${isRelQuery}`);
  
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // TASK B: If relationship query but NO active relationship, return guidance immediately
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  if (isRelQuery && !hasActiveRelationship) {
    const guidanceReply = `Åu an bu iliÅŸki aktif deÄŸil ${genderPronoun}. "Relationship Upload" panelinden iliÅŸkiyi aktif edersen son mesajlara bakabilirim. Hangi iliÅŸkiyle ilgili konuÅŸmak istiyorsun?`;
    
    console.log(`[${uid}] ğŸš« Returning guidance for inactive relationship query`);
    
    // Save to history
    await saveConversationHistory(uid, sessionId, safeMessage, guidanceReply, {
      messages: Array.isArray(rawHistory?.messages) ? rawHistory.messages : [],
      summary: rawHistory?.summary ?? null,
      lastSummaryAt: rawHistory?.lastSummaryAt ?? null,
    }).catch((e) => console.error(`[${uid}] History save error â†’`, e));
    
    return {
      reply: guidanceReply,
      extractedTraits,
      outcomePrediction: undefined,
      patterns: undefined,
      meta: {
        intent,
        model: "none",
        premium: isPremium,
        messageCount: userProfile.messageCount,
        processingTime: Date.now() - startTime,
        hadError: false,
        errorType: null,
        inactiveRelationshipGuidance: true,
      },
    };
  }

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // VISION SUPPORT: EÄŸer imageUrl varsa, user message'Ä± vision formatÄ±nda gÃ¶nder
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  let userMessageContent;
  
  if (imageUrl) {
    // Vision API formatÄ±: content array ile
    userMessageContent = [
      {
        type: "text",
        text: safeMessage || "Bu resimle ilgili ne dÃ¼ÅŸÃ¼nÃ¼yorsun?",
      },
      {
        type: "image_url",
        image_url: {
          url: imageUrl,
          detail: "auto", // "low", "high", "auto"
        },
      },
    ];
    console.log(`[${uid}] ğŸ“¸ Image attached to message â†’ Vision mode enabled`);
  } else {
    // Normal text message
    userMessageContent = safeMessage;
  }

  const contextMessages = [
    ...systemMessages,
    ...recentHistory,
    { role: "user", content: userMessageContent },
  ];

  let replyText = null;
  let openaiError = null;

  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  // MODULE 2.5: ROBUST OPENAI CALL WITH RETRY + FALLBACK
  // â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  let originalModel = model;
  let usedFallback = false;

  console.log(`[${uid}] Calling OpenAI with robust retry â†’ ${model}`);

  const openaiResult = await callOpenAIWithRetry(uid, model, contextMessages, maxTokens);
  
  replyText = openaiResult.replyText;
  model = openaiResult.model;
  originalModel = openaiResult.originalModel;
  usedFallback = openaiResult.usedFallback;
  
  if (openaiResult.hadError) {
    openaiError = openaiResult.errorType;
  }

  // FALLBACK REPLY
  if (!replyText) {
    replyText =
      "Sistem ÅŸu an cevap Ã¼retemedi kanka. Bir daha dene, bu sefer olacak. ğŸ’ª";
    console.warn(`[${uid}] Fallback reply used â†’ ${openaiError}`);
  } else {
    // STEP 3: Check if response is too generic/empty (OUTPUT GUARD)
    const isGeneric = checkIfGenericResponse(replyText);
    
    if (isGeneric) {
      console.log(`[${uid}] âš ï¸ Generic response detected, retrying with stronger prompt`);
      
      // Add stronger instruction and retry ONCE
      const retryMessages = [
        ...contextMessages.slice(0, -1), // All except last user message
        {
          role: "system",
          content: `
âš ï¸ CRITICAL QUALITY INSTRUCTION:
Previous response was too generic/vague. This time:
â€¢ Be CONCRETE and SPECIFIC
â€¢ Give 1-3 ACTIONABLE steps
â€¢ Ask MAX 1 clarifying question if truly needed
â€¢ NO filler phrases ("BuradayÄ±m", "YardÄ±mcÄ± olabilirim", etc.)
â€¢ Get straight to the point
          `.trim()
        },
        contextMessages[contextMessages.length - 1] // Last user message
      ];
      
      try {
        const retryCompletion = await openai.chat.completions.create({
          model,
          messages: retryMessages,
          max_completion_tokens: maxTokens,
          temperature: 0.4,
        });
        
        if (retryCompletion?.choices?.[0]?.message?.content) {
          const retryReply = retryCompletion.choices[0].message.content.trim();
          if (retryReply && retryReply.length > 10) {
            replyText = retryReply;
            console.log(`[${uid}] âœ… Generic retry successful â†’ Reply length: ${replyText.length}`);
          }
        }
      } catch (retryError) {
        console.error(`[${uid}] Generic retry failed, keeping original response:`, retryError?.message);
      }
    }
  }

  /**
   * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   * FIRESTORE-SAFE HISTORY SAVE FIX
   * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
   * lastSummaryAt, summary, messagesâ€¦ hiÃ§bir alan artÄ±k undefined kalamaz.
   */

  const safeHistoryObject = {
    messages: Array.isArray(rawHistory?.messages)
      ? rawHistory.messages
      : [],
    summary: rawHistory?.summary ?? null,
    lastSummaryAt: rawHistory?.lastSummaryAt ?? null,
  };

  await saveConversationHistory(uid, sessionId, safeMessage, replyText, safeHistoryObject).catch(
    (e) => console.error(`[${uid}] History save error â†’`, e)
  );

  const processingTime = Date.now() - startTime;

  console.log(
    `[${uid}] âœ… DONE (${processingTime}ms) â†’ Success: ${!openaiError}`
  );

  return {
    reply: replyText,
    extractedTraits,
    outcomePrediction: isPremium ? outcomePrediction : undefined,
    patterns: isPremium ? patterns : undefined,
    meta: {
      intent,
      model,
      originalModel,
      usedFallback,
      premium: isPremium,
      messageCount: userProfile.messageCount,
      processingTime,
      hadError: !!openaiError,
      errorType: openaiError,
    },
  };
}

/**
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * PATCH C: Check if relationship context was recently changed
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * Returns true if relationship was updated in the last 2 minutes
 * This indicates a toggle ON or relationship switch in same chat
 */
async function checkRelationshipContextChange(uid, relationshipId, relationshipUpdatedAt) {
  try {
    // Get user doc to check last known relationship state
    const userDoc = await firestore.collection("users").doc(uid).get();
    const userData = userDoc.data();
    
    if (!userData) return false;
    
    // Parse relationship updatedAt timestamp
    let relationshipTimestamp = null;
    if (relationshipUpdatedAt) {
      if (relationshipUpdatedAt.toDate) {
        relationshipTimestamp = relationshipUpdatedAt.toDate();
      } else if (relationshipUpdatedAt._seconds) {
        relationshipTimestamp = new Date(relationshipUpdatedAt._seconds * 1000);
      } else if (typeof relationshipUpdatedAt === "string") {
        relationshipTimestamp = new Date(relationshipUpdatedAt);
      }
    }
    
    if (!relationshipTimestamp) return false;
    
    // Check if relationship was updated in last 2 minutes
    const twoMinutesAgo = new Date(Date.now() - 2 * 60 * 1000);
    const isRecentlyUpdated = relationshipTimestamp > twoMinutesAgo;
    
    if (isRecentlyUpdated) {
      console.log(`[${uid}] Relationship recently updated: ${relationshipTimestamp.toISOString()}`);
      return true;
    }
    
    // Also check if activeRelationshipId changed recently
    const lastKnownRelId = userData.lastKnownRelationshipId;
    if (lastKnownRelId && lastKnownRelId !== relationshipId) {
      console.log(`[${uid}] Relationship ID changed: ${lastKnownRelId} â†’ ${relationshipId}`);
      
      // Update last known relationship ID
      await firestore.collection("users").doc(uid).set({
        lastKnownRelationshipId: relationshipId,
      }, { merge: true });
      
      return true;
    }
    
    // If this is first time seeing this relationship ID, store it
    if (!lastKnownRelId) {
      await firestore.collection("users").doc(uid).set({
        lastKnownRelationshipId: relationshipId,
      }, { merge: true });
    }
    
    return false;
  } catch (error) {
    console.error(`[${uid}] Error checking relationship context change:`, error);
    return false; // Safe default
  }
}

/**
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * STEP 3: Check if response is too generic/empty (OUTPUT GUARD)
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * Returns true if response lacks actionable content
 */
function checkIfGenericResponse(text) {
  if (!text || text.length < 10) {
    return true; // Too short
  }
  
  // Forbidden filler phrases that indicate generic response
  const fillerPhrases = [
    "buradayÄ±m",
    "seni dinliyorum",
    "yardÄ±mcÄ± olabilirim",
    "baÅŸka bir ÅŸey var mÄ±",
    "ne dÃ¼ÅŸÃ¼nÃ¼yorsun",
    "umarÄ±m beÄŸenirsin",
    "ihtiyacÄ±n olan her ÅŸey",
  ];
  
  const lowerText = text.toLowerCase();
  
  // Count how many filler phrases are present
  const fillerCount = fillerPhrases.filter(phrase => lowerText.includes(phrase)).length;
  
  // If response is short AND has filler phrases, it's generic
  if (text.length < 100 && fillerCount >= 2) {
    return true;
  }
  
  // If response has 3+ filler phrases regardless of length, it's generic
  if (fillerCount >= 3) {
    return true;
  }
  
  return false;
}